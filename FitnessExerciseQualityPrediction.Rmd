---
title: "Fitness Exercise Quality Analysis Based on Accelerometer Data"
author: "VS"
date: "October 25, 2015"
output: 
        html_document:
                keep_md: true
---

## Overview

A prediction model is built and cross-validated based on the supplied "pml-training.csv" data file containing the outcome of the quality of exercise activity as a function of a subset of the large number of covariates based on a combination of instructions for the assignment, exploratory data analysis, and a dash of common sense.
  
The model is analyzed for its accuracy based on the cross-validation results, and then applied to the supplied "pml-testing.csv" test data.

## Methodology

### Covariate Selection

The instructions for the assignment suggest that we focus on accelerometer data.  Unfortunately, no data dictionary appears to be available that describes the input data, so we select the parameters according to the following criteria:  
1. Pick the set of variables whose names contain the string "accel".  
2. Remove the variables whose values are observed to contain a large number of empty (NA) values, as these will clearly contribute nothing, irrespective of their importance.  
3. Sanity-check the other variables that may have had a relevance even though their names did not contain the string "accel", and confirm that their values are largely missing.  
4. After running the training and cross-validation based on the selected variables, sanity-check the resulting accuracy.  

### Cross-validation Methodology

The training data is split into a train and test set in an 70-30 ratio.  

Note that the "testing" data is not intended to be used for cross-validation, it is only used for final testing.

### Training Method

The "Random Forest" algorithm is used as the training method, as the problem domain is amenable to this best-practice algorithm that is observed to out-perform other algorithms in practice.  Since the algorithm is slow, the training results are cached in a file for iterative processing and reproducibility.

## Implementation And Output

Read the training and test data, subset the columns to the variables of interest, taking care to remove irrelevant variables (such as ID, user_name, etc.) that can cause interference with the Random Forest algorithm.
```{r echo=TRUE}
library(caret)
pml_training = read.csv("./data/pml-training.csv");
pml_final_test = read.csv("./data/pml-testing.csv");
# do variable subsetting to produce training and final test sets
pml_acc_trainset = pml_training[, c("classe", grep("^accel_|^total_accel", names(pml_training),value=T))]
pml_acc_final_testset=pml_final_test[,grep("^accel_|^total_accel_", names(pml_training),value=T)]
#since final test set doesn't have the classe column, add one with N/A values
classe=rep(NA, nrow(pml_acc_final_testset))
pml_acc_final_testset=cbind(classe, pml_acc_final_testset)

```

Split the training data into training and cross-validation testing sets, generate the prediction model, observe the errors, cross-validate
```{r echo=TRUE}
set.seed(12345)
inTrain = createDataPartition(y=pml_acc_trainset$classe, p=0.7, list=F)
training = pml_acc_trainset[inTrain, ]
testing = pml_acc_trainset[-inTrain, ]
if (file.exists("./data/modelFit.rds")) {
        modelFit = readRDS("./data/modelFit.rds")
} else {
        modelFit = train(classe ~ ., data=training, method="rf")
        saveRDS(modelFit, "./data/modelFit.rds")
}
#Display the fitted model with resampling errors etc.
print(modelFit)
#Cross-validate
cvPredictions = predict(modelFit, newdata=testing)
#Display the confusion matrix to observe the accuracy of the prediction accuracy
print(confusionMatrix(cvPredictions, testing$classe))
```

The resampling errors and prediction accuracy generated from the above look reasonable.  

Now, apply the prediction model to the final testing set and save as well as display the final predictions:
```{r echo=TRUE}
finalPredictions=predict(modelFit, newdata=pml_acc_final_testset)
# save the predictions in a file, and also display the data
pml_write_files = function(x) {
        n = length(x)
        for (i in 1:n) {
                filename=paste0("problem_id_",i,".txt")
                write.table(x[i], file=filename, quote=F, row.names=F, col.names=F)
        }
}
pml_write_files(finalPredictions)
print(finalPredictions)
```

The end.
